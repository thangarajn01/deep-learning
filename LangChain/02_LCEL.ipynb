{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d7a2ad",
   "metadata": {},
   "source": [
    "# LangChain Expression Language (LCEL) Deepdive\n",
    "LangChain Expression Language (LCEL) offers several key advantages over legacy chains:\n",
    "\n",
    "1. **Composability**: LCEL allows you to easily combine different components using the | operator, making chain creation more intuitive and readable\n",
    "2. **Type Safety**: LCEL provides better type checking and validation between components, reducing runtime errors\n",
    "3. **Streaming Support**: Built-in streaming capabilities that work consistently across different components\n",
    "4. **Flexible Input/Output**: Components can handle various input/output types and automatically convert between them when possible\n",
    "5. **Better Testing**: The modular nature makes it easier to test individual components and mock dependencies\n",
    "6. **Runtime Optimization**: LCEL can automatically optimize execution paths and handle caching more efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43d97001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95d3df6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What did the ice cream cone say to the scoop? \\n\\n“I’m so glad we’re together, I’m just so cone-fident about our relationship!”'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "output_parser = StrOutputParser() # This is a custom class that is used to parse the output of the model.\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# Pipe in python is __or__ and __ror__ dunder methods, which are bitwise operators used for overloading. \n",
    "# Overloading in Python refers to the ability to have multiple methods and custom classes with the same name but different implementations.\n",
    "\n",
    "chain.invoke({\"topic\": \"ice cream\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f0d984",
   "metadata": {},
   "source": [
    "Each component in the chain is a callable/runnable object that can be chained together using the | operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2995807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='tell me a short joke about ice cream', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"topic\": \"ice cream\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46f27db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the ice cream truck break down?  \\n\\nBecause it had a rocky road!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 15, 'total_tokens': 32, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BeLGiDTHxcWfN8ekK3ion7GzO2iPL', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3e8ca0af-022b-4df6-8c6c-14d78f9145ee-0', usage_metadata={'input_tokens': 15, 'output_tokens': 17, 'total_tokens': 32, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages.human import HumanMessage\n",
    "\n",
    "messages = [HumanMessage(content='tell me a short joke about ice cream')]\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e3bfe0",
   "metadata": {},
   "source": [
    "## CRunnable\n",
    "\n",
    "1. **Abstract Base Class Pattern**:\n",
    "    - `CRunnable` is an abstract class that defines a common interface for processing data. \n",
    "    - Any subclass must implement the `process()` method, ensuring consistent behavior across different runnable objects.\n",
    "\n",
    "2. **Chain of Responsibility Implementation**:\n",
    "    - Each `CRunnable` can be linked to another through the `next` attribute. \n",
    "    - When `invoke()` is called, it processes the data and automatically passes the result to the next runnable in the chain if one exists.\n",
    "\n",
    "3. **Pipe Operator Overloading**:\n",
    "    - The `__or__` method allows you to chain runnables using the `|` operator (e.g., `runnable1 | runnable2`).\n",
    "    - Creating a more readable syntax for building processing pipelines.\n",
    "\n",
    "4. **Sequence Wrapper Class**:\n",
    "    - `CRunnableSequence` is a specialized runnable that wraps two other runnables, executing them in sequence. \n",
    "    - It bypasses the normal `process()` method and directly chains the `invoke()` calls from first to second runnable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd792357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class CRunnable(ABC): # CRunnable is an abstract class that defines the interface for a runnable object.\n",
    "    def __init__(self):\n",
    "        self.next = None # next is the argument to the constructor of the class.\n",
    "\n",
    "    @abstractmethod # This is a decorator that ensures that the method is implemented by subclasses.\n",
    "    def process(self, data):\n",
    "        \"\"\"\n",
    "        This method must be implemented by subclasses to define\n",
    "        data processing behavior.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def invoke(self, data):\n",
    "        processed_data = self.process(data)\n",
    "        if self.next is not None:\n",
    "            return self.next.invoke(processed_data)\n",
    "        return processed_data\n",
    "\n",
    "    def __or__(self, other):\n",
    "        return CRunnableSequence(self, other)\n",
    "    \n",
    "class CRunnableSequence(CRunnable):\n",
    "    def __init__(self, first, second):\n",
    "        super().__init__()\n",
    "        self.first = first\n",
    "        self.second = second\n",
    "\n",
    "    def process(self, data):\n",
    "        pass\n",
    "\n",
    "    def invoke(self, data):\n",
    "        first_result = self.first.invoke(data)\n",
    "        return self.second.invoke(first_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee78c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddTen(CRunnable): # CRunnable is inherited from the abstract class ABC.\n",
    "    def process(self, data):\n",
    "        print(\"AddTen: \", data)\n",
    "        return data + 10\n",
    "\n",
    "class MultiplyByTwo(CRunnable):\n",
    "    def process(self, data):\n",
    "        print(\"Multiply by 2: \", data)\n",
    "        return data * 2\n",
    "\n",
    "class ConvertToString(CRunnable):\n",
    "    def process(self, data):\n",
    "        print(\"Convert to string: \", data)\n",
    "        return f\"Result: {data}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a745e210",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AddTen()\n",
    "b = MultiplyByTwo()\n",
    "c = ConvertToString()\n",
    "\n",
    "chain = a | b | c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ce06832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AddTen:  10\n",
      "Multiply by 2:  20\n",
      "Convert to string:  40\n",
      "Result: 40\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke(10)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1fe1f1",
   "metadata": {},
   "source": [
    "## Runnables from LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eed4abca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc5dae02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RunnablePassthrough does nothing but pass the input through to the next runnable.\n",
    "chain = RunnablePassthrough() | RunnablePassthrough () | RunnablePassthrough ()\n",
    "chain.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "102e470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_to_upper(input: str):\n",
    "    output = input.upper()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e02736d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HELLO'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = RunnablePassthrough() | RunnableLambda(input_to_upper) | RunnablePassthrough()\n",
    "chain.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8c2744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel({\"x\": RunnablePassthrough(), \"y\": RunnablePassthrough()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4be18ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 'hello', 'y': 'hello'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee025cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': {'input': 'hello', 'input2': 'goodbye'},\n",
       " 'y': {'input': 'hello', 'input2': 'goodbye'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42509758",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel({\"x\": RunnablePassthrough(), \"y\": lambda z: z[\"input2\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3b35b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': {'input': 'hello', 'input2': 'goodbye'}, 'y': 'goodbye'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83cd1c6",
   "metadata": {},
   "source": [
    "### Nested Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1963c2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_keys_to_uppercase(input: dict):\n",
    "    output = input.get(\"input\", \"not found\").upper()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aece241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel({\"x\": RunnablePassthrough() | RunnableLambda(find_keys_to_uppercase), \"y\": lambda z: z[\"input2\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21f17ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 'HELLO', 'y': 'goodbye'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a794044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel({\"x\": RunnablePassthrough()})\n",
    "\n",
    "def assign_func(_):\n",
    "    return 100\n",
    "\n",
    "def multiply(input):\n",
    "    return input * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2254113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': {'input': 'hello', 'input2': 'goodbye'}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cba02dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel({\"x\": RunnablePassthrough()}).assign(extra=RunnableLambda(assign_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a4eb594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': {'input': 'hello', 'input2': 'goodbye'}, 'extra': 100}\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4e15cc",
   "metadata": {},
   "source": [
    "### Combine Multiple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb908625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor(input: dict):\n",
    "    return input.get(\"extra\", \"Key not found\")\n",
    "\n",
    "def cupper(upper: str):\n",
    "    return str(upper).upper()\n",
    "\n",
    "new_chain = RunnableLambda(extractor) | RunnableLambda(cupper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ad158aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TEST'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chain.invoke({\"extra\": \"test\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66c093e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain = chain | new_chain\n",
    "final_chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91fdb68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
