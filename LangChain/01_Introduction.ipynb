{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71755df4",
   "metadata": {},
   "source": [
    "# Content\n",
    "* LangChain Introduction: Features and Why it is needed\n",
    "* OpenAI Basic Integration: OpenAI API Usage, Text Generation\n",
    "* Creating Converstaions with langchain_openai library\n",
    "* Prompt Templates: prompts, few shot prompts, chain-of-thought prompts, compositions, serialization\n",
    "* Output Parsers: Response Schemas, RouterOutputParsers.\n",
    "* Chains: Simple Chains, Chains with multiple inputs, Chaining mulitple chains, Making LLM to decide follow up Chain using LLMRouterChain, MultiPromptChain\n",
    "* Memory: ChatMessageHistory, ConversationBufferMemory, ConversationChain, ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d45b4",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "LangChain is a versatile framework for building applications that leverage large language models (LLMs). It is designed to simplify the integration of various tools and components, making it an excellent choice for creating chatbots, complex workflows, and more.\n",
    "\n",
    "1. **Modular Architecture**\n",
    "    * Compose complex workflows by combining tools like models, memory, and external APIs.\n",
    "    * Easily chain tasks for multi-step processes.\n",
    "\n",
    "2. **Advanced Prompt Engineering**\n",
    "   * Use PromptTemplates for dynamic prompt creation.\n",
    "   * Supports few-shot and zero-shot learning to enhance model performance.\n",
    "   * Different formats: JSONs, YAML\n",
    "\n",
    "3. **Tool Integration**\n",
    "    * Seamlessly integrate APIs, databases, and vector stores.\n",
    "    * Enhance functionalities with external knowledge sources.\n",
    "\n",
    "4. **Memory Management** \n",
    "    * Manage context in multi-turn conversations.\n",
    "    * Develop chatbots that remember user interactions.\n",
    "\n",
    "5. **Multi-step Task Chaining**\n",
    "    * Link multiple operations in a single workflow.\n",
    "\n",
    "6. **Model Agnosticism**    \n",
    "    * Compatible with OpenAI models, Hugging Face models, and custom LLMs.\n",
    "\n",
    "7. **Retrieval-Augmented Generation (RAG)**\n",
    "    * Combine LLMs with retrieval tools to pull context-specific information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fcc5c9",
   "metadata": {},
   "source": [
    "## OpenAI Basic Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8de46b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (1.82.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from openai) (2.11.5)\n",
      "Requirement already satisfied: sniffio in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: dotenv in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from dotenv) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d3059f",
   "metadata": {},
   "source": [
    "**Load the API Key from env**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f2ec7d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/LangChain\n",
      "API key found: sk-p...qb0A\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Print the current working directory to verify where Python is looking for the .env file\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Print the API key (first few characters for security)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if api_key:\n",
    "    print(\"API key found:\", api_key[:4] + \"...\" + api_key[-4:])\n",
    "else:\n",
    "    print(\"No API key found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a7626f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful assistant specialized in providing information about BellaVista Italian Restaurant.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms on the menu?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massistant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBellaVista offers a variety of Italian dishes including pasta, pizza, and seafood.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDo you have vegan options?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages/openai/_utils/_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py:925\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    922\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    923\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    924\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages/openai/_base_client.py:1239\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1226\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1227\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1236\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1237\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1238\u001b[0m     )\n\u001b[0;32m-> 1239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages/openai/_base_client.py:969\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    967\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    975\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1226\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1223\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1225\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1101\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in providing information about BellaVista Italian Restaurant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What's on the menu?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"BellaVista offers a variety of Italian dishes including pasta, pizza, and seafood.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Do you have vegan options?\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ab239d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-Bdz0DzMY5DI4jcwaLhz6DHRicoDNW',\n",
       " 'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'message': {'content': 'Yes, BellaVista Italian Restaurant typically offers vegan options on their menu. Common vegan choices may include salads, vegetable-based pasta dishes, and pizzas without cheese. Its always a good idea to ask your server for specific vegan options available during your visit.',\n",
       "    'refusal': None,\n",
       "    'role': 'assistant',\n",
       "    'annotations': [],\n",
       "    'audio': None,\n",
       "    'function_call': None,\n",
       "    'tool_calls': None}}],\n",
       " 'created': 1748868985,\n",
       " 'model': 'gpt-4o-mini-2024-07-18',\n",
       " 'object': 'chat.completion',\n",
       " 'service_tier': 'default',\n",
       " 'system_fingerprint': 'fp_34a54ae93c',\n",
       " 'usage': {'completion_tokens': 50,\n",
       "  'prompt_tokens': 61,\n",
       "  'total_tokens': 111,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ac0bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, BellaVista Italian Restaurant typically offers vegan options on their menu. Common vegan choices may include salads, vegetable-based pasta dishes, and pizzas without cheese. Its always a good idea to ask your server for specific vegan options available during your visit.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c28a0e",
   "metadata": {},
   "source": [
    "## Creating a conversation with SystemMessage, AIMessage and HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dc8f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_openai in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (0.3.18)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.61 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain_openai) (0.3.63)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain_openai) (1.82.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.61->langchain_openai) (0.3.43)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.61->langchain_openai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.61->langchain_openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.61->langchain_openai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.61->langchain_openai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.61->langchain_openai) (4.13.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.61->langchain_openai) (2.11.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.61->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain_openai) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain_openai) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain_openai) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain_openai) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain_openai) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain_openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain_openai) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain_openai) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain_openai) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.61->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.61->langchain_openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.61->langchain_openai) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain_openai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain_openai) (2.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain) (0.3.63)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain) (0.3.43)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain) (2.11.5)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.41-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain) (6.0.2)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading sqlalchemy-2.0.41-cp39-cp39-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: SQLAlchemy, async-timeout, langchain-text-splitters, langchain\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m4/4\u001b[0m [langchain]/4\u001b[0m [langchain]\n",
      "\u001b[1A\u001b[2KSuccessfully installed SQLAlchemy-2.0.41 async-timeout-4.0.3 langchain-0.3.25 langchain-text-splitters-0.3.8\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_openai\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fb4baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d100393e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Why do cows have hooves instead of feet? \\n\\nBecause they lactose!' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 13, 'total_tokens': 28, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BdzwT8F36SYnvKbAEVKlutmLRh7MR', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--1060f406-e194-4928-af49-281f711405f9-0' usage_metadata={'input_tokens': 13, 'output_tokens': 15, 'total_tokens': 28, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"Tell me a joke about cows\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558a6904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant specialized in providing information about BellaVista Italian Restaurant.\"),\n",
    "    HumanMessage(content=\"What's on the menu?\"),\n",
    "    AIMessage(content=\"BellaVista offers a variety of Italian dishes including pasta, pizza, and seafood.\"),\n",
    "    HumanMessage(content=\"Do you have vegan options?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aebdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Yes, BellaVista Italian Restaurant typically offers vegan options, including dishes such as vegan pasta, salads, and vegetable-based pizzas. It's always a good idea to check the specific menu or ask the staff for the latest vegan offerings.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 61, 'total_tokens': 106, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-Be0R1BncznC8TJT74QpfYshFQM3Wt', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--0fa4c3e7-74d2-45db-bd53-6089cf4ec10b-0', usage_metadata={'input_tokens': 61, 'output_tokens': 45, 'total_tokens': 106, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result = llm.invoke(input=messages)\n",
    "llm_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91078159",
   "metadata": {},
   "source": [
    "### Batch Processing for Chat Models - Make Multiple Requests at Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8ce20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[ChatGeneration(generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='    ?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 27, 'total_tokens': 43, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-Be0ULv4XTArUN2bVKp26C3pHvsRDj', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--676a3867-9642-42d0-b271-ac337f61302c-0', usage_metadata={'input_tokens': 27, 'output_tokens': 16, 'total_tokens': 43, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), text='    ?')], [ChatGeneration(generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='     ?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 29, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-Be0UMB7s1qmf5bt2GtSRV9ZwbbXFV', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--361be61b-a551-4aa7-9faa-97246c8a8946-0', usage_metadata={'input_tokens': 29, 'output_tokens': 10, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), text='     ?')]], llm_output={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 56, 'total_tokens': 82, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_34a54ae93c'}, run=[RunInfo(run_id=UUID('676a3867-9642-42d0-b271-ac337f61302c')), RunInfo(run_id=UUID('361be61b-a551-4aa7-9faa-97246c8a8946'))], type='LLMResult')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_messages = [\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful assistant that translates English to Tamil\"),\n",
    "        HumanMessage(content=\"Do you have vegan options?\")\n",
    "    ],\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful assistant that translates the English to Hindi.\"),\n",
    "        HumanMessage(content=\"Do you have vegan options?\")\n",
    "    ],\n",
    "]\n",
    "batch_result = llm.generate(batch_messages)\n",
    "batch_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80f3473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.outputs.llm_result.LLMResult'>\n"
     ]
    }
   ],
   "source": [
    "print(type(batch_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b091c1",
   "metadata": {},
   "source": [
    "Extracting the output ourself (we will later take a look at Output-Parsers!)\n",
    "\n",
    "1. LLMResult is the top-level object that contains a list of generations.\n",
    "2. Each of those elements is itself a list of Generation (or ChatGeneration) objects.\n",
    "3. The code expects batch_result to be an LLMResult object that has a .generations attribute (which is a list of lists of Generation objects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a04aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbatch_result = LLMResult(\\n    generations=[\\n        # First input's generations\\n        [ChatGeneration(text='Haben Sie vegane Optionen?', ...)], # This is generation[0] for the first batch item\\n        # Second input's generations\\n        [ChatGeneration(text='Tienen opciones veganas?', ...)]  # This is generation[0] for the second batch item\\n    ],\\n    # ... other LLMResult attributes\\n)\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "batch_result = LLMResult(\n",
    "    generations=[\n",
    "        # First input's generations\n",
    "        [ChatGeneration(text='Haben Sie vegane Optionen?', ...)], # This is generation[0] for the first batch item\n",
    "        # Second input's generations\n",
    "        [ChatGeneration(text='Tienen opciones veganas?', ...)]  # This is generation[0] for the second batch item\n",
    "    ],\n",
    "    # ... other LLMResult attributes\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d4e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['    ?',\n",
       " '     ?']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations = [gen_text[0].text for gen_text in batch_result.generations]\n",
    "translations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfe51ef",
   "metadata": {},
   "source": [
    "## Prompt Template\n",
    "**Prompt**: Prompt allow you to create System Messages with input variables, for example, this: SystemMessage(content=\"You are a helpful assistant that translates the English to Spanish.\") English and Spanish may be dynamic. This can be archieved with templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaed3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "You are a helpful assistant that translates the {input_language} to {output_language}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233059e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou are a helpful assistant that translates the english to german\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "# Creating a PromptTemplate object from the TEMPLATE string\n",
    "prompt_template = PromptTemplate.from_template( \n",
    "    template=TEMPLATE\n",
    ")\n",
    "prompt_template.format(input_language=\"english\", output_language=\"german\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44f0a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou are a helpful assistant that translates the english to german\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passing the input_variables to the constructor will provide additional validation for the template\n",
    "prompt_template = PromptTemplate(template=TEMPLATE, input_variables=[\"input_language\", \"output_language\"])\n",
    "prompt_template.format(input_language=\"english\", output_language=\"german\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b330d603",
   "metadata": {},
   "source": [
    "### Few Shot Prompt - Provide some examples in the template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab59e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEW_SHOT_TEMPLATE = \"\"\"\n",
    "Analyze the sentiment and subject of the given text.\n",
    "\n",
    "Instructions:\n",
    "1. Sentiment Analysis: Determine if the text expresses a positive, neutral, or negative sentiment\n",
    "2. Subject Identification: Extract the main subject as a single word\n",
    "\n",
    "Please provide the analysis in JSON format with these fields:\n",
    "- sentiment: \"positive\", \"neutral\", or \"negative\"\n",
    "- subject: single word describing the main topic\n",
    "\n",
    "text: {input}\n",
    "\"\"\"\n",
    "\n",
    "# To improve performance we can provide examples to increase the quality of the output.\n",
    "\n",
    "FEW_SHOT_TEMPLATE = \"\"\"\n",
    "Interpret the text and evaluate the text.\n",
    "sentiment: is the text in a positive, neutral or negative sentiment?\n",
    "subject: What subject is the text about? Use exactly one word.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "sentiment\n",
    "subject\n",
    "\n",
    "text: {input}\n",
    "\n",
    "Examples:\n",
    "text: The BellaVista restaurant offers an exquisite dining experience. The flavors are rich and the presentation is impeccable.\n",
    "sentiment: positive\n",
    "subject: BellaVista\n",
    "\n",
    "text: BellaVista restaurant was alright. The food was decent, but nothing stood out.\n",
    "sentiment: neutral\n",
    "subject: BellaVista\n",
    "\n",
    "text: I was disappointed with BellaVista. The service was slow and the dishes lacked flavor.\n",
    "sentiment: negative\n",
    "subject: BellaVista\n",
    "\n",
    "text: SeoulSavor offered the most authentic Korean flavors I've tasted outside of Seoul. The kimchi was perfectly fermented and spicy.\n",
    "sentiment: positive\n",
    "subject: SeoulSavor\n",
    "\n",
    "text: SeoulSavor was okay. The bibimbap was good but the bulgogi was a bit too sweet for my taste.\n",
    "sentiment: neutral\n",
    "subject: SeoulSavor\n",
    "\n",
    "text: I didn't enjoy my meal at SeoulSavor. The tteokbokki was too mushy and the service was not attentive.\n",
    "sentiment: negative\n",
    "subject: SeoulSavor\n",
    "\n",
    "text: MunichMeals has the best bratwurst and sauerkraut I've tasted outside of Bavaria. Their beer garden ambiance is truly authentic.\n",
    "sentiment: positive\n",
    "subject: MunichMeals\n",
    "\n",
    "text: MunichMeals was alright. The weisswurst was okay, but I've had better elsewhere.\n",
    "sentiment: neutral\n",
    "subject: MunichMeals\n",
    "\n",
    "text: I was let down by MunichMeals. The potato salad lacked flavor and the staff seemed uninterested.\n",
    "sentiment: negative\n",
    "subject: MunichMeals\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159898a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnalyze the sentiment and subject of the given text.\\n\\nInstructions:\\n1. Sentiment Analysis: Determine if the text expresses a positive, neutral, or negative sentiment\\n2. Subject Identification: Extract the main subject as a single word\\n\\nPlease provide the analysis in JSON format with these fields:\\n- sentiment: \"positive\", \"neutral\", or \"negative\"\\n- subject: single word describing the main topic\\n\\ntext: The MunichDeals experience was just awesome!\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(template=FEW_SHOT_TEMPLATE, input_variables=[\"input\"])\n",
    "prompt_template.format(input=\"The MunichDeals experience was just awesome!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e150cbc9",
   "metadata": {},
   "source": [
    "LangChain also provides a **FewShotPromptTemplate** class, which allows creating the examples more modularized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffea9eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"text\": \"The BellaVista restaurant offers an exquisite dining experience. The flavors are rich and the presentation is impeccable.\",\n",
    "        \"response\": \"sentiment: positive\\nsubject: BellaVista\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"BellaVista restaurant was alright. The food was decent, but nothing stood out.\",\n",
    "        \"response\": \"sentiment: neutral\\nsubject: BellaVista\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"I was disappointed with BellaVista. The pasta was overcooked and the sauces lacked flavor.\",\n",
    "        \"response\": \"sentiment: negative\\nsubject: BellaVista\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"SeoulSavor offered the most authentic Korean flavors I've tasted outside of Seoul. The kimchi was perfectly fermented and spicy.\",\n",
    "        \"response\": \"sentiment: positive\\nsubject: SeoulSavor\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"I didn't enjoy my meal at SeoulSavor. The tteokbokki was too mushy and the service was not attentive.\",\n",
    "        \"response\": \"sentiment: negative\\nsubject: SeoulSavor\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"MunichMeals has the best bratwurst and sauerkraut I've tasted outside of Bavaria. Their beer garden ambiance is truly authentic.\",\n",
    "        \"response\": \"sentiment: positive\\nsubject: MunichMeals\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"I was let down by MunichMeals. The potato salad lacked flavor and the staff seemed uninterested.\",\n",
    "        \"response\": \"sentiment: negative\\nsubject: MunichMeals\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6dd04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_example = {\n",
    "    \"text\": \"SeoulSavor was okay. The bibimbap was good but the bulgogi was a bit too sweet for my taste.\",\n",
    "    \"response\": \"sentiment: neutral\\nsubject: SeoulSavor\"\n",
    "}\n",
    "examples.append(new_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef0530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate(input_variables=[\"text\", \"response\"], template=\"Text: {text}\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863a3b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"text: {input}\",\n",
    "    input_variables=[\"input\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0676634c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The BellaVista restaurant offers an exquisite dining experience. The flavors are rich and the presentation is impeccable.\n",
      "sentiment: positive\n",
      "subject: BellaVista\n",
      "\n",
      "Text: BellaVista restaurant was alright. The food was decent, but nothing stood out.\n",
      "sentiment: neutral\n",
      "subject: BellaVista\n",
      "\n",
      "Text: I was disappointed with BellaVista. The pasta was overcooked and the sauces lacked flavor.\n",
      "sentiment: negative\n",
      "subject: BellaVista\n",
      "\n",
      "Text: SeoulSavor offered the most authentic Korean flavors I've tasted outside of Seoul. The kimchi was perfectly fermented and spicy.\n",
      "sentiment: positive\n",
      "subject: SeoulSavor\n",
      "\n",
      "Text: I didn't enjoy my meal at SeoulSavor. The tteokbokki was too mushy and the service was not attentive.\n",
      "sentiment: negative\n",
      "subject: SeoulSavor\n",
      "\n",
      "Text: MunichMeals has the best bratwurst and sauerkraut I've tasted outside of Bavaria. Their beer garden ambiance is truly authentic.\n",
      "sentiment: positive\n",
      "subject: MunichMeals\n",
      "\n",
      "Text: I was let down by MunichMeals. The potato salad lacked flavor and the staff seemed uninterested.\n",
      "sentiment: negative\n",
      "subject: MunichMeals\n",
      "\n",
      "Text: SeoulSavor was okay. The bibimbap was good but the bulgogi was a bit too sweet for my taste.\n",
      "sentiment: neutral\n",
      "subject: SeoulSavor\n",
      "\n",
      "text: The MunichDeals experience was just awesome!\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(input=\"The MunichDeals experience was just awesome!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35325b57",
   "metadata": {},
   "source": [
    "### Chain-of-Thought (CoT) Prompting\n",
    "Instead of just providing examples, we can also provide examples which include the whole thought process of why a review is negative, neutral or positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcec49ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "COT_PROMPT_TEMPLATE = \"\"\"\n",
    "Interpret the text and evaluate the text. Determine if the text has a positive, neutral, or negative sentiment. Also, identify the subject of the text in one word.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "sentiment\n",
    "subject\n",
    "\n",
    "text: {input}\n",
    "\n",
    "Chain-of-Thought Prompts:\n",
    "Let's start by evaluating a statement. Consider: \"The BellaVista restaurant offers an exquisite dining experience. The flavors are rich and the presentation is impeccable.\" How does this make you feel about BellaVista?\n",
    " It sounds like a positive review for BellaVista.\n",
    "\n",
    "Based on the positive nature of that statement, how would you format your response?\n",
    " { \"sentiment\": \"positive\", \"subject\": \"BellaVista\" }\n",
    "\n",
    "Now, think about this: \"SeoulSavor was okay. The bibimbap was good but the bulgogi was a bit too sweet for my taste.\" Does this give a strong feeling either way?\n",
    " Not particularly. It seems like a mix of good and not-so-good elements, so it's neutral.\n",
    "\n",
    "Given the neutral sentiment, how should this be presented?\n",
    " { \"sentiment\": \"neutral\", \"subject\": \"SeoulSavor\" }\n",
    "\n",
    "Lastly, ponder on this: \"I was let down by MunichMeals. The potato salad lacked flavor and the staff seemed uninterested.\" What's the overall impression here?\n",
    " The statement is expressing disappointment and dissatisfaction.\n",
    "\n",
    "And if you were to categorize this impression, what would it be?\n",
    " { \"sentiment\": \"negative\", \"subject\": \"MunichMeals\" }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f90035",
   "metadata": {},
   "source": [
    "### Composition\n",
    "You can also compose multiple prompts together. This can be especially useful if you want to reuse parts of prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77283eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5j/lxcm95dd6297n4glc7hvs9b40000gn/T/ipykernel_19215/3054282885.py:41: LangChainDeprecationWarning: This class is deprecated. Please see the docstring below or at the link for a replacement option: https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.pipeline.PipelinePromptTemplate.html\n",
      "  pipeline_prompt = PipelinePromptTemplate(final_prompt=full_prompt, pipeline_prompts=input_prompts)\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "# Introduction\n",
    "introduction_template = \"\"\"\n",
    "Interpret the text and evaluate the text. Determine if the text has a positive, neutral, or negative sentiment. Also, identify the subject of the text in one word.\n",
    "\"\"\"\n",
    "introduction_prompt = PromptTemplate.from_template(introduction_template)\n",
    "\n",
    "# Example\n",
    "example_template = \"\"\"\n",
    "Chain-of-Thought Prompts:\n",
    "Let's start by evaluating a statement. Consider: \"{example_text}\". How does this make you feel about {example_subject}?\n",
    "Response: {example_evaluation}\n",
    "\n",
    "Based on the {example_sentiment} nature of that statement, how would you format your response?\n",
    "Response: {example_format}\n",
    "\"\"\"\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "# Execution\n",
    "execution_template = \"\"\"\n",
    "Now, execute this process for the text: \"{input}\".\n",
    "\"\"\"\n",
    "execution_prompt = PromptTemplate.from_template(execution_template)\n",
    "\n",
    "# Composing the full prompt\n",
    "full_template = \"\"\"\n",
    "{introduction}\n",
    "{example}\n",
    "{execution} \"\"\"\n",
    "\n",
    "full_prompt = PromptTemplate.from_template(full_template)\n",
    "\n",
    "# PipelinePrompts\n",
    "input_prompts = [\n",
    "    (\"introduction\", introduction_prompt),\n",
    "    (\"example\", example_prompt),\n",
    "    (\"execution\", execution_prompt)\n",
    "]\n",
    "pipeline_prompt = PipelinePromptTemplate(final_prompt=full_prompt, pipeline_prompts=input_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdfb1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Interpret the text and evaluate the text. Determine if the text has a positive, neutral, or negative sentiment. Also, identify the subject of the text in one word.\n",
      "\n",
      "\n",
      "Chain-of-Thought Prompts:\n",
      "Let's start by evaluating a statement. Consider: \"The BellaVista restaurant offers an exquisite dining experience. The flavors are rich and the presentation is impeccable.\". How does this make you feel about BellaVista?\n",
      "Response: It sounds like a positive review for BellaVista.\n",
      "\n",
      "Based on the positive nature of that statement, how would you format your response?\n",
      "Response: { \"sentiment\": \"positive\", \"subject\": \"BellaVista\" }\n",
      "\n",
      "\n",
      "Now, execute this process for the text: \"The new restaurant downtown has bland dishes and the wait time is too long.\".\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(pipeline_prompt.format(\n",
    "    example_text=\"The BellaVista restaurant offers an exquisite dining experience. The flavors are rich and the presentation is impeccable.\",\n",
    "    example_subject=\"BellaVista\",\n",
    "    example_evaluation=\"It sounds like a positive review for BellaVista.\",\n",
    "    example_sentiment=\"positive\",\n",
    "    example_format='{ \"sentiment\": \"positive\", \"subject\": \"BellaVista\" }',\n",
    "    input=\"The new restaurant downtown has bland dishes and the wait time is too long.\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c7020f",
   "metadata": {},
   "source": [
    "### Serailizing Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb60dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(input_variables=[\"input\"], template=\"Tell me a joke about {input}\")\n",
    "prompt.save(\"prompt.yaml\")\n",
    "prompt.save(\"prompt.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee02dfa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a joke about chickens'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import load_prompt\n",
    "\n",
    "prompt = load_prompt(\"prompt.yaml\")\n",
    "prompt.format(input=\"chickens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5239fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a joke about cows'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = load_prompt(\"prompt.json\")\n",
    "prompt.format(input=\"cows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6fcf11",
   "metadata": {},
   "source": [
    "# Chains\n",
    "Instead of just using models you can combine a model and a prompt. This can be done with the **LLMChain** class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f13738dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "Interprete the text and evaluate the text.\n",
    "sentiment: is the text in a positive, neutral or negative sentiment? Sentiment is required.\n",
    "subject: What subject is the text about? Use exactly one word. Use 'None' if no subject was provided.\n",
    "price: How much did the customer pay? Use 'None' if no price was provided.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "sentiment\n",
    "subject\n",
    "price\n",
    "\n",
    "text: {input}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb6b1552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'I ordered pizza salami from the restaurant Bellavista. It was ok, but the dough could have been a bit more crisp.',\n",
       " 'text': '```json\\n{\\n  \"sentiment\": \"neutral\",\\n  \"subject\": \"pizza\",\\n  \"price\": \"None\"\\n}\\n```'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template=TEMPLATE)\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "chain.invoke(input=\"I ordered pizza salami from the restaurant Bellavista. It was ok, but the dough could have been a bit more crisp.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e19da83",
   "metadata": {},
   "source": [
    "## Response Schemas\n",
    "\n",
    "There were two issues with the output: The output also contains text and the output is just a string, not a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "90f9ae89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResponseSchema(name='sentiment', description='is the text in a positive, neutral or negative sentiment? Sentiment is required.', type='string'), ResponseSchema(name='subject', description='What subject is the text about? Use exactly one word. Use None if no price was provided.', type='string'), ResponseSchema(name='price', description='How much did the customer pay? Use None if no price was provided.', type='float')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"sentiment\", description=\"is the text in a positive, neutral or negative sentiment? Sentiment is required.\"),\n",
    "    ResponseSchema(name=\"subject\", description=\"What subject is the text about? Use exactly one word. Use None if no price was provided.\"),\n",
    "    ResponseSchema(name=\"price\", description=\"How much did the customer pay? Use None if no price was provided.\", type=\"float\") # type can be string, float, int, bool, list, dict, etc.\n",
    "]\n",
    "print(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ab5fa8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"sentiment\": string  // is the text in a positive, neutral or negative sentiment? Sentiment is required.\n",
      "\t\"subject\": string  // What subject is the text about? Use exactly one word. Use None if no price was provided.\n",
      "\t\"price\": float  // How much did the customer pay? Use None if no price was provided.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bce00941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt template\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"Interprete the text and evaluate the text. \"\n",
    "            \"sentiment: is the text in a positive, neutral or negative sentiment? \"\n",
    "            \"subject: What subject is the text about? Use exactly one word. \"\n",
    "            \"Just return the JSON, do not add ANYTHING, NO INTERPRETATION! \"\n",
    "            \"text: {input}\\n\"\n",
    "            \"{format_instructions}\\n\"\n",
    "        )\n",
    "    ],\n",
    "    input_variables=[\"input\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions} # Useful when you want to use the same prompt for different output formats\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "89777904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='Interprete the text and evaluate the text. sentiment: is the text in a positive, neutral or negative sentiment? subject: What subject is the text about? Use exactly one word. Just return the JSON, do not add ANYTHING, NO INTERPRETATION! text: I ordered pizza salami from the restaurant Bellavista. It was ok, but the dough could have been a bit more crisp.\\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"sentiment\": string  // is the text in a positive, neutral or negative sentiment? Sentiment is required.\\n\\t\"subject\": string  // What subject is the text about? Use exactly one word. Use None if no price was provided.\\n\\t\"price\": float  // How much did the customer pay? Use None if no price was provided.\\n}\\n```\\n', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "_input = prompt.format_prompt(input=\"I ordered pizza salami from the restaurant Bellavista. It was ok, but the dough could have been a bit more crisp.\")\n",
    "print(_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "58e1d210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmessages = [\\n    SystemMessage(\\n        content=\\'Interprete the text and evaluate the text. sentiment: is the text in a positive, neutral or negative sentiment? \\'\\n        \\'subject: What subject is the text about? Use exactly one word. Just return the JSON, do not add ANYTHING, NO INTERPRETATION! \\'\\n        \\'text: I ordered pizza salami from the restaurant Bellavista. It was ok, but the dough could have been a bit more crisp.\\n\\'\\n        \\'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n\\'\\n        \\'```json\\n\\'\\n        \\'{\\n\\'\\n        \\'\\t\"sentiment\": string  // is the text in a positive, neutral or negative sentiment? Sentiment is required.\\n\\'\\n        \\'\\t\"subject\": string  // What subject is the text about? Use exactly one word. Use None if no price was provided.\\n\\'\\n        \\'\\t\"price\": float  // How much did the customer pay? Use None if no price was provided.\\n\\'\\n        \\'}\\n\\'\\n        \\'```\\n\\',\\n        additional_kwargs={}, # It\\'s commonly used to store extra information that might be specific to certain LLM providers or custom implementations\\n        response_metadata={} # Token usage etc.\\n    )\\n]\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content='Interprete the text and evaluate the text. sentiment: is the text in a positive, neutral or negative sentiment? '\n",
    "        'subject: What subject is the text about? Use exactly one word. Just return the JSON, do not add ANYTHING, NO INTERPRETATION! '\n",
    "        'text: I ordered pizza salami from the restaurant Bellavista. It was ok, but the dough could have been a bit more crisp.\\n'\n",
    "        'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n'\n",
    "        '```json\\n'\n",
    "        '{\\n'\n",
    "        '\\t\"sentiment\": string  // is the text in a positive, neutral or negative sentiment? Sentiment is required.\\n'\n",
    "        '\\t\"subject\": string  // What subject is the text about? Use exactly one word. Use None if no price was provided.\\n'\n",
    "        '\\t\"price\": float  // How much did the customer pay? Use None if no price was provided.\\n'\n",
    "        '}\\n'\n",
    "        '```\\n',\n",
    "        additional_kwargs={}, # It's commonly used to store extra information that might be specific to certain LLM providers or custom implementations\n",
    "        response_metadata={} # Token usage etc.\n",
    "    )\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "90ca6c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"sentiment\": \"neutral\",\n",
      "\t\"subject\": \"pizza\",\n",
      "\t\"price\": null\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# to_messages() converts the input to a list of messages. If the list has more than one message, the LLM will be called multiple times.\n",
    "output = llm.invoke(_input.to_messages())\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1bf2ee38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentiment': 'neutral', 'subject': 'pizza', 'price': None}\n"
     ]
    }
   ],
   "source": [
    "json_output = parser.parse(output.content)\n",
    "print(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "71a08242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_output.get(\"sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e9dfeb",
   "metadata": {},
   "source": [
    "## Chains with Multiple Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "52301406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'a parrot',\n",
       " 'text': 'Why did the parrot sit on the computer?\\n\\nBecause it wanted to keep an eye on the mouse!'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"input\"], template=\"Tell me a joke about {input}\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "chain.invoke(input=\"a parrot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a743dc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'a parrot',\n",
       " 'language': 'Tamil',\n",
       " 'text': ' parroth  ,      , \"        !   !\"  \\n\\n( ,   !)  \\n\\n(           !)'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(input_variables=[\"input\", \"language\"], template=\"Tell me a joke about {input} in {language}\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "chain.invoke({\"input\": \"a parrot\", \"language\": \"Tamil\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed9d8b4",
   "metadata": {},
   "source": [
    "## Sequential Chains\n",
    "\n",
    "Chains can be more complex and not all sequential chains will be as simple as passing a single string as an argument and getting a single string as output for all steps in the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1bd22867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.sequential import SequentialChain\n",
    "\n",
    "# This is an LLMChain to write a review given a dish name and the experience.\n",
    "prompt_review = PromptTemplate.from_template(\n",
    "    template=\"You ordered {dish_name} and your experience was {experience}. Write a review: \"\n",
    ")\n",
    "chain_review = LLMChain(llm=llm, prompt=prompt_review, output_key=\"review\")\n",
    "\n",
    "# This is an LLMChain to write a follow-up comment given the restaurant review.\n",
    "prompt_comment = PromptTemplate.from_template(\n",
    "    template=\"Given the restaurant review: {review}, write a follow-up comment: \"\n",
    ")\n",
    "chain_comment = LLMChain(llm=llm, prompt=prompt_comment, output_key=\"comment\")\n",
    "\n",
    "# This is an LLMChain to summarize a review.\n",
    "prompt_summary = PromptTemplate.from_template(\n",
    "    template=\"Summarise the review in one short sentence: \\n\\n {comment}\"\n",
    ")\n",
    "chain_summary = LLMChain(llm=llm, prompt=prompt_summary, output_key=\"summary\")\n",
    "\n",
    "# This is an LLMChain to translate a summary into German.\n",
    "prompt_translation = PromptTemplate.from_template(\n",
    "    template=\"Translate the summary to Tamil: \\n\\n {summary}\"\n",
    ")\n",
    "chain_translation = LLMChain(\n",
    "    llm=llm, prompt=prompt_translation, output_key=\"tamil_translation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c26dfa3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dish_name': 'Pizza Salami',\n",
       " 'experience': 'It was awful!',\n",
       " 'review': 'Title: Disappointing Experience with Pizza Salami\\n\\nI recently ordered a Pizza Salami, expecting a delicious, classic pizza experience, but I was unfortunately met with a series of disappointments. \\n\\nFirst off, the delivery was late, which is always a frustrating start to any meal. When the pizza finally arrived, it was lukewarm at best. A hot pizza is essential for enjoying all the flavors, and this one missed the mark right out of the gate.\\n\\nNow, onto the pizza itself. The crust was far too thick and doughy, lacking the crispy texture that makes a pizza enjoyable. The sauce was bland and didnt provide the rich, robust flavor I anticipated. Most disappointing was the salami; it was greasy and had an overpowering taste that overshadowed any other ingredients. It felt more like a fast-food pizza than anything artisanal or homemade.\\n\\nAdditionally, the cheese was sparse, which left the whole thing feeling unbalanced and lacking that gooey, satisfying quality that great pizza usually has. \\n\\nAll in all, my experience with the Pizza Salami was far from satisfactory. I would not recommend it, and I doubt Ill be ordering from this place again. I was really hoping for a delicious meal, but it turned out to be a regrettable choice. Hopefully, they can improve in the future, but for now, Ill be looking elsewhere for my pizza fix.',\n",
       " 'comment': \"Thank you for sharing your detailed review! Its always disappointing when an anticipated meal doesn't meet your expectations. Your feedback on the late delivery and the quality of the pizza itself really highlights some areas the restaurant could focus on for improvement. A good pizza experience relies heavily on not just the taste, but also the temperature and balance of flavors, so its unfortunate that this one missed the mark in multiple ways.\\n\\nHave you considered reaching out to the restaurant directly to express your concerns? Sometimes establishments appreciate feedback and may even offer ways to make it right. Hopefully, you find a place that delivers the delicious pizza experience you're looking for!\",\n",
       " 'summary': 'The review expresses disappointment with a pizza experience due to late delivery and poor quality, suggesting the restaurant could improve based on the feedback and encouraging direct communication with them.',\n",
       " 'tamil_translation': ' ,          .        ,      .'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_review, chain_comment, chain_summary, chain_translation],\n",
    "    input_variables=[\"dish_name\", \"experience\"],\n",
    "    output_variables=[\"review\", \"comment\", \"summary\", \"tamil_translation\"],\n",
    ")\n",
    "\n",
    "overall_chain.invoke({\"dish_name\": \"Pizza Salami\", \"experience\": \"It was awful!\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73678000",
   "metadata": {},
   "source": [
    "## Instead of Chaining multiple chains together, let LLM to decide which follow up chain is being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b697fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "\n",
    "positive_template = \"\"\"You are an AI that focuses on the positive side of things. \\\n",
    "Whenever you analyze a text, you look for the positive aspects and highlight them. \\\n",
    "Here is the text:\n",
    "{input}\"\"\"\n",
    "\n",
    "neutral_template = \"\"\"You are an AI that has a neutral perspective. You just provide a balanced analysis of the text, \\\n",
    "not favoring any positive or negative aspects. Here is the text:\n",
    "{input}\"\"\"\n",
    "\n",
    "negative_template = \"\"\"You are an AI that is designed to find the negative aspects in a text. \\\n",
    "You analyze a text and show the potential downsides. Here is the text:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f4a34452",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"positive\",\n",
    "        \"description\": \"Good for analyzing positive sentiments\",\n",
    "        \"prompt_template\": positive_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"neutral\",\n",
    "        \"description\": \"Good for analyzing neutral sentiments\",\n",
    "        \"prompt_template\": neutral_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"negative\",\n",
    "        \"description\": \"Good for analyzing negative sentiments\",\n",
    "        \"prompt_template\": negative_template,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2b441b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='You are an AI that focuses on the positive side of things. Whenever you analyze a text, you look for the positive aspects and highlight them. Here is the text:\\n{input}'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x10f1fd4c0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10e472cd0>, root_client=<openai.OpenAI object at 0x10dfa6070>, root_async_client=<openai.AsyncOpenAI object at 0x10a5eb9a0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}),\n",
       " 'neutral': LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='You are an AI that has a neutral perspective. You just provide a balanced analysis of the text, not favoring any positive or negative aspects. Here is the text:\\n{input}'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x10f1fd4c0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10e472cd0>, root_client=<openai.OpenAI object at 0x10dfa6070>, root_async_client=<openai.AsyncOpenAI object at 0x10a5eb9a0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}),\n",
       " 'negative': LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='You are an AI that is designed to find the negative aspects in a text. You analyze a text and show the potential downsides. Here is the text:\\n{input}'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x10f1fd4c0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10e472cd0>, root_client=<openai.OpenAI object at 0x10dfa6070>, root_async_client=<openai.AsyncOpenAI object at 0x10a5eb9a0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={})}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    # Here we are creating a dictionary of chains, where the key is the name of the chain and the value is the chain itself.\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "destination_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "53ef08f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive: Good for analyzing positive sentiments\n",
      "neutral: Good for analyzing neutral sentiments\n",
      "negative: Good for analyzing negative sentiments\n"
     ]
    }
   ],
   "source": [
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "print(destinations_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fa3ba666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5j/lxcm95dd6297n4glc7hvs9b40000gn/T/ipykernel_19215/731848241.py:10: LangChainDeprecationWarning: Please see migration guide here for recommended implementation: https://python.langchain.com/docs/versions/migrating_chains/multi_prompt_chain/\n",
      "  chain = MultiPromptChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "negative: {'input': 'I ordered Pizza Salami for 9.99$, and it was not good!'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'I ordered Pizza Salami for 9.99$, and it was not good!',\n",
       " 'text': 'Here are the potential downsides identified in the text:\\n\\n1. **Quality of Food**: The pizza was described as \"not good,\" indicating that the taste or quality did not meet expectations.\\n\\n2. **Value for Money**: At a price of $9.99, the expectation for a satisfactory product is typically high. The poor quality suggests that it may not have been worth the money spent.\\n\\n3. **Negative Experience**: The statement reflects disappointment, which can lead to an overall negative dining experience and dissatisfaction with the restaurant.\\n\\n4. **Potential Waste**: If the pizza was inedible or not enjoyable, it could result in wasted food, which is both a financial and environmental concern.\\n\\n5. **Impact on Future Orders**: Such an experience might deter the individual from ordering from the same place again, leading to loss of potential repeat business for the restaurant.\\n\\n6. **Lack of Variety**: If the Pizza Salami was poorly made, one might infer that other menu items could also be subpar, limiting choices. \\n\\n7. **Expectation vs. Reality**: The experience may highlight a gap between what was expected based on the price or previous experiences and the actual quality received, leading to frustration. \\n\\nOverall, the text conveys a negative experience related to food quality, value, and potential implications for future dining decisions.'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(), # RouterOutputParser is used to parse the output of the router chain into a dictionary\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)\n",
    "\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=destination_chains[\"neutral\"],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.invoke({\"input\": \"I ordered Pizza Salami for 9.99$ and it was not good!\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceac723c",
   "metadata": {},
   "source": [
    "# Memory\n",
    "In some applications like chatbots, it is important to remember previous interactions to keep the whole context of a conversation. Memory does provide you an easy way to handle this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f2ba6eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain-community) (0.3.63)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain-community) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain-community) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.12.7-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain-community) (0.3.43)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting numpy>=1.26.2 (from langchain-community)\n",
      "  Using cached numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached frozenlist-1.6.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached multidict-6.4.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached propcache-0.3.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached yarl-1.20.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (72 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.12.7-cp39-cp39-macosx_11_0_arm64.whl (465 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached multidict-6.4.4-cp39-cp39-macosx_11_0_arm64.whl (38 kB)\n",
      "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.20.0-cp39-cp39-macosx_11_0_arm64.whl (95 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.6.0-cp39-cp39-macosx_11_0_arm64.whl (122 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\n",
      "Using cached propcache-0.3.1-cp39-cp39-macosx_11_0_arm64.whl (46 kB)\n",
      "Installing collected packages: propcache, numpy, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, attrs, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-community\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m16/16\u001b[0m [langchain-community]ngchain-community]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.7 aiosignal-1.3.2 attrs-25.3.0 dataclasses-json-0.6.7 frozenlist-1.6.0 httpx-sse-0.4.0 langchain-community-0.3.24 marshmallow-3.26.1 multidict-6.4.4 mypy-extensions-1.1.0 numpy-2.0.2 propcache-0.3.1 pydantic-settings-2.9.1 typing-inspect-0.9.0 yarl-1.20.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43808c58",
   "metadata": {},
   "source": [
    "## ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eb8e34a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='hello my friend!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_user_message(\"hi!\")\n",
    "history.add_ai_message(\"hello my friend!\")\n",
    "history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027cfe0e",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2451a6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: hi!\\nAI: hello my friend!\\nHuman: How are you?'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# ConversationBufferMemory is a memory that stores the conversation in a buffer.\n",
    "# It is a simple memory that stores the conversation in a dictionary.\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"hello my friend!\")\n",
    "memory.chat_memory.add_user_message(\"How are you?\")\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e8be08",
   "metadata": {},
   "source": [
    "## ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d709f84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: What is the capital of France?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the capital of France?',\n",
       " 'history': '',\n",
       " 'response': \"The capital of France is Paris! It's known for its iconic landmarks like the Eiffel Tower, the Louvre Museum, and the Notre-Dame Cathedral. Paris is also famous for its rich history, art, fashion, and cuisine. Have you ever been to Paris, or is it on your travel list?\"}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, verbose=True, memory=ConversationBufferMemory()\n",
    ")\n",
    "\n",
    "conversation.invoke(input=\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4e284477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is the capital of France?\n",
      "AI: The capital of France is Paris! It's known for its iconic landmarks like the Eiffel Tower, the Louvre Museum, and the Notre-Dame Cathedral. Paris is also famous for its rich history, art, fashion, and cuisine. Have you ever been to Paris, or is it on your travel list?\n",
      "Human: Whats the best food there?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Whats the best food there?',\n",
       " 'history': \"Human: What is the capital of France?\\nAI: The capital of France is Paris! It's known for its iconic landmarks like the Eiffel Tower, the Louvre Museum, and the Notre-Dame Cathedral. Paris is also famous for its rich history, art, fashion, and cuisine. Have you ever been to Paris, or is it on your travel list?\",\n",
       " 'response': \"Paris is a culinary paradise with a wide array of delicious foods to try! Some of the best dishes include:\\n\\n1. **Croissants** - Flaky, buttery pastries that are perfect for breakfast.\\n2. **Baguettes** - Freshly baked bread that is a staple in French cuisine.\\n3. **Coq au Vin** - A classic French dish made with chicken braised in red wine, mushrooms, and lardons.\\n4. **Ratatouille** - A vegetable dish made with eggplant, zucchini, bell peppers, and tomatoes, often served as a side or main course.\\n5. **Escargots de Bourgogne** - Snails cooked in garlic butter, a delicacy for adventurous eaters.\\n6. **Crpes** - Thin pancakes that can be filled with sweet or savory ingredients, like Nutella or ham and cheese.\\n7. **Macarons** - Colorful, delicate meringue cookies filled with ganache or buttercream, perfect for a sweet treat.\\n\\nAnd of course, you can't forget about the cheese and wine! Paris has countless fromageries and wine shops where you can sample local varieties. Do any of these dishes sound appealing to you?\"}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"Whats the best food there?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23be8ad4",
   "metadata": {},
   "source": [
    "## ConversationSummaryBufferMemory\n",
    "When inputs get long, we might not want to send the whole conversation, but rather a summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a2bd8603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "review = \"I ordered Pizza Salami for 9.99$ and it was awesome! \\\n",
    "The pizza was delivered on time and was still hot when I received it. \\\n",
    "The crust was thin and crispy, and the toppings were fresh and flavorful. \\\n",
    "The Salami was well-cooked and complemented the cheese perfectly. \\\n",
    "The price was reasonable and I believe I got my money's worth. \\\n",
    "Overall, I am very satisfied with my order and I would recommend this pizza place to others.\"\n",
    "\n",
    "summary_memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=50) # If Token is 1000, no summary will be created\n",
    "summary_memory.save_context(\n",
    "    {\"input\": \"Hello, how can I help you today?\"},\n",
    "    {\"output\": \"Could you analyze a review for me?\"},\n",
    ")\n",
    "summary_memory.save_context(\n",
    "    {\"input\": \"Sure, I'd be happy to. Could you provide the review?\"},\n",
    "    {\"output\": f\"{review}\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "752cb32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human greets the AI and asks how they can help. The AI requests an analysis of a review, which the human agrees to provide. The AI then shares a positive review about a Pizza Salami order, highlighting timely delivery, hot temperature, thin and crispy crust, fresh toppings, well-cooked salami, reasonable price, and overall satisfaction, recommending the pizza place to others.\n",
      "Human: Thank you very much!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Thank you very much!',\n",
       " 'history': 'System: The human greets the AI and asks how they can help. The AI requests an analysis of a review, which the human agrees to provide. The AI then shares a positive review about a Pizza Salami order, highlighting timely delivery, hot temperature, thin and crispy crust, fresh toppings, well-cooked salami, reasonable price, and overall satisfaction, recommending the pizza place to others.',\n",
       " 'response': \"You're very welcome! I'm glad you found the review helpful. If you have any specific aspects you'd like to analyze further or if you need assistance with anything else, just let me know! Whether it's about the pizza place, other food reviews, or something entirely different, I'm here to help!\"}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, verbose=True, memory=summary_memory\n",
    ")\n",
    "\n",
    "conversation.invoke(input=\"Thank you very much!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "687387f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: hi!\\nAI: hello my friend!\\nHuman: How are you?'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a1014695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello! I'd like to get your opinion on a restaurant review I received.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello! I'd like to get your opinion on a restaurant review I received.\n",
      "AI: Of course! I'd be happy to help you with that. Please share the review, and let me know what specific aspects you're looking for feedback on. Are you curious about the overall tone, the details mentioned, or something else?\n",
      "Human: Sure, I'd be happy to help! Could you share the review with me?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human asks for the AI's opinion on a restaurant review they received.\n",
      "AI: Of course! I'd be happy to help you with that. Please share the review, and let me know what specific aspects you're looking for feedback on. Are you curious about the overall tone, the details mentioned, or something else?\n",
      "Human: Sure, I'd be happy to help! Could you share the review with me?\n",
      "AI: It seems there was a little mix-up! I don't have the review you mentioned. If you could provide the text of the review, I can give you my thoughts on it. Just let me know what aspects you're particularly interested in, like the writing style, the food descriptions, or the overall impression!\n",
      "Human: Here's the review: I ordered Pizza Salami for 9.99$ and it was awesome! \n",
      "The pizza was delivered on time and was still hot when I received it. \n",
      "The crust was thin and crispy, and the toppings were fresh and flavorful. \n",
      "The Salami was well-cooked and complemented the cheese perfectly. \n",
      "The price was reasonable and I believe I got my money's worth. \n",
      "Overall, I am very satisfied with my order and I would recommend this pizza place to others.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human asks for the AI's opinion on a restaurant review they received. The AI expresses willingness to help and requests the review text along with specific aspects for feedback. The human shares a positive review about a Pizza Salami order, highlighting timely delivery, quality of the pizza, reasonable price, and overall satisfaction. The AI analyzes the review, noting its enthusiastic tone, detailed descriptions, appealing food qualities, value for money, and strong recommendation. The AI suggests that adding personal anecdotes or details about the restaurant's atmosphere could enhance the review, but overall considers it well-written and effective in conveying a positive dining experience.\n",
      "Human: What aspects of the review stood out to you?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human asks for the AI's opinion on a restaurant review they received. The AI expresses willingness to help and requests the review text along with specific aspects for feedback. The human shares a positive review about a Pizza Salami order, highlighting timely delivery, quality of the pizza, reasonable price, and overall satisfaction. The AI analyzes the review, noting its enthusiastic tone, detailed descriptions, appealing food qualities, value for money, and strong recommendation. The AI suggests that adding personal anecdotes or details about the restaurant's atmosphere could enhance the review, but overall considers it well-written and effective in conveying a positive dining experience. The human then asks what aspects of the review stood out to the AI, which identifies the enthusiastic tone, detailed descriptions, timely delivery, reasonable price, and strong recommendation as key elements that create a compelling and persuasive review. The AI offers to explore any specific part of the review further.\n",
      "Human: Do you think the price of 9.99$ is reasonable for this pizza?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human asks for the AI's opinion on a restaurant review they received. The AI expresses willingness to help and requests the review text along with specific aspects for feedback. The human shares a positive review about a Pizza Salami order, highlighting timely delivery, quality of the pizza, reasonable price, and overall satisfaction. The AI analyzes the review, noting its enthusiastic tone, detailed descriptions, appealing food qualities, value for money, and strong recommendation. The AI suggests that adding personal anecdotes or details about the restaurant's atmosphere could enhance the review, but overall considers it well-written and effective in conveying a positive dining experience. The human then asks what aspects of the review stood out to the AI, which identifies the enthusiastic tone, detailed descriptions, timely delivery, reasonable price, and strong recommendation as key elements that create a compelling and persuasive review. The AI offers to explore any specific part of the review further. The human inquires whether the AI thinks the price of $9.99 is reasonable for the pizza.\n",
      "AI: The price of $9.99 for a pizza can be considered reasonable, especially if the quality of the ingredients and the overall experience match the expectations set by the review. Factors like the size of the pizza, the type of toppings (like Salami), and the local market prices for similar offerings can also influence whether that price feels fair. If the pizza is well-made, delicious, and delivered promptly, then $9.99 seems like a good deal! Additionally, if the review mentions that the pizza exceeded expectations in terms of taste and quality, that further supports the idea that the price is justified. Would you like to discuss any other aspects of the review or the restaurant?\n",
      "Human: Would you recommend this restaurant based on the review?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human asks for the AI's opinion on a restaurant review they received. The AI expresses willingness to help and requests the review text along with specific aspects for feedback. The human shares a positive review about a Pizza Salami order, highlighting timely delivery, quality of the pizza, reasonable price, and overall satisfaction. The AI analyzes the review, noting its enthusiastic tone, detailed descriptions, appealing food qualities, value for money, and strong recommendation. The AI suggests that adding personal anecdotes or details about the restaurant's atmosphere could enhance the review, but overall considers it well-written and effective in conveying a positive dining experience. The human then asks what aspects of the review stood out to the AI, which identifies the enthusiastic tone, detailed descriptions, timely delivery, reasonable price, and strong recommendation as key elements that create a compelling and persuasive review. The AI offers to explore any specific part of the review further. The human inquires whether the AI thinks the price of $9.99 is reasonable for the pizza. The AI responds that $9.99 can be considered reasonable if the quality of the ingredients and overall experience match expectations, noting that factors like pizza size, toppings, and local market prices influence the perception of fairness. The AI concludes that if the pizza exceeded expectations in taste and quality, then the price is justified and offers to discuss other aspects of the review or restaurant.\n",
      "Human: Would you recommend this restaurant based on the review?\n",
      "AI: Based on the positive review you shared, I would definitely recommend this restaurant! The review highlights several key factors that contribute to a great dining experience, such as timely delivery, high-quality pizza, and a reasonable price. The enthusiastic tone and strong recommendation from the reviewer suggest that they had a very satisfying experience, which is a good indicator for potential customers. If the restaurant consistently delivers on these aspects, it seems like a solid choice for anyone craving pizza. Would you like to know more about what to look for in restaurant reviews or perhaps explore other dining options?\n",
      "Human: What other information would you have liked to see in the review?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Exchange 1:\n",
      "Input: Hello! I'd like to get your opinion on a restaurant review I received.\n",
      "Response: Of course! I'd be happy to help you with that. Please share the review, and let me know what specific aspects you're looking for feedback on. Are you curious about the overall tone, the details mentioned, or something else?\n",
      "History: \n",
      "\n",
      "Exchange 2:\n",
      "Input: Sure, I'd be happy to help! Could you share the review with me?\n",
      "Response: It seems there was a little mix-up! I don't have the review you mentioned. If you could provide the text of the review, I can give you my thoughts on it. Just let me know what aspects you're particularly interested in, like the writing style, the food descriptions, or the overall impression!\n",
      "History: Human: Hello! I'd like to get your opinion on a restaurant review I received.\n",
      "AI: Of course! I'd be happy to help you with that. Please share the review, and let me know what specific aspects you're looking for feedback on. Are you curious about the overall tone, the details mentioned, or something else?\n",
      "\n",
      "Exchange 3:\n",
      "Input: Here's the review: I ordered Pizza Salami for 9.99$ and it was awesome! \n",
      "The pizza was delivered on time and was still hot when I received it. \n",
      "The crust was thin and crispy, and the toppings were fresh and flavorful. \n",
      "The Salami was well-cooked and complemented the cheese perfectly. \n",
      "The price was reasonable and I believe I got my money's worth. \n",
      "Overall, I am very satisfied with my order and I would recommend this pizza place to others.\n",
      "Response: Thank you for sharing the review! It sounds like a positive experience overall. Here are some specific aspects to consider:\n",
      "\n",
      "1. **Overall Tone**: The tone of the review is very enthusiastic and satisfied. Phrases like \"it was awesome!\" and \"I am very satisfied\" convey a strong sense of approval, which is great for potential customers.\n",
      "\n",
      "2. **Details Mentioned**: The reviewer provides specific details about their order, such as the type of pizza (Pizza Salami), the price ($9.99), and the quality of the delivery (on time and hot). This level of detail helps readers visualize the experience and can influence their decision to try the restaurant.\n",
      "\n",
      "3. **Food Descriptions**: The descriptions of the crust being \"thin and crispy\" and the toppings being \"fresh and flavorful\" are appealing and likely to attract pizza lovers. The mention of the Salami being \"well-cooked\" and complementing the cheese adds to the overall positive impression of the food.\n",
      "\n",
      "4. **Value for Money**: The reviewer emphasizes that the price was reasonable and that they felt they got their money's worth. This is an important factor for many customers, as it suggests that the restaurant offers good quality at a fair price.\n",
      "\n",
      "5. **Recommendation**: The final note about recommending the pizza place to others is a strong endorsement. It indicates that the reviewer not only enjoyed their meal but also believes others would too, which can be very persuasive for potential customers.\n",
      "\n",
      "Overall, this review is well-written and effectively communicates a positive dining experience. If you're looking for feedback on how to improve it, perhaps encouraging the reviewer to include more personal anecdotes or specific details about the restaurant's atmosphere could add depth. But as it stands, it's a solid review!\n",
      "History: System: The human asks for the AI's opinion on a restaurant review they received.\n",
      "AI: Of course! I'd be happy to help you with that. Please share the review, and let me know what specific aspects you're looking for feedback on. Are you curious about the overall tone, the details mentioned, or something else?\n",
      "Human: Sure, I'd be happy to help! Could you share the review with me?\n",
      "AI: It seems there was a little mix-up! I don't have the review you mentioned. If you could provide the text of the review, I can give you my thoughts on it. Just let me know what aspects you're particularly interested in, like the writing style, the food descriptions, or the overall impression!\n",
      "\n",
      "Exchange 4:\n",
      "Input: What aspects of the review stood out to you?\n",
      "Response: Several aspects of the review really stood out to me! First, the enthusiastic tone conveyed a genuine sense of satisfaction, which is always engaging for readers. The detailed descriptions of the Pizza Salami, particularly the quality, helped paint a vivid picture of the food, making it more appealing. \n",
      "\n",
      "Additionally, the mention of timely delivery is crucial, as it highlights the restaurant's efficiency and reliability, which are important factors for many diners. The reasonable price point adds to the overall value proposition, making it clear that the reviewer felt they received a good deal for the quality of food they enjoyed.\n",
      "\n",
      "Lastly, the strong recommendation at the end serves as a powerful endorsement, encouraging others to try the restaurant. Overall, these elements combined create a compelling and persuasive review that effectively communicates a positive dining experience. Would you like to explore any specific part of the review further?\n",
      "History: System: The human asks for the AI's opinion on a restaurant review they received. The AI expresses willingness to help and requests the review text along with specific aspects for feedback. The human shares a positive review about a Pizza Salami order, highlighting timely delivery, quality of the pizza, reasonable price, and overall satisfaction. The AI analyzes the review, noting its enthusiastic tone, detailed descriptions, appealing food qualities, value for money, and strong recommendation. The AI suggests that adding personal anecdotes or details about the restaurant's atmosphere could enhance the review, but overall considers it well-written and effective in conveying a positive dining experience.\n",
      "\n",
      "Exchange 5:\n",
      "Input: Do you think the price of 9.99$ is reasonable for this pizza?\n",
      "Response: The price of $9.99 for a pizza can be considered reasonable, especially if the quality of the ingredients and the overall experience match the expectations set by the review. Factors like the size of the pizza, the type of toppings (like Salami), and the local market prices for similar offerings can also influence whether that price feels fair. If the pizza is well-made, delicious, and delivered promptly, then $9.99 seems like a good deal! Additionally, if the review mentions that the pizza exceeded expectations in terms of taste and quality, that further supports the idea that the price is justified. Would you like to discuss any other aspects of the review or the restaurant?\n",
      "History: System: The human asks for the AI's opinion on a restaurant review they received. The AI expresses willingness to help and requests the review text along with specific aspects for feedback. The human shares a positive review about a Pizza Salami order, highlighting timely delivery, quality of the pizza, reasonable price, and overall satisfaction. The AI analyzes the review, noting its enthusiastic tone, detailed descriptions, appealing food qualities, value for money, and strong recommendation. The AI suggests that adding personal anecdotes or details about the restaurant's atmosphere could enhance the review, but overall considers it well-written and effective in conveying a positive dining experience. The human then asks what aspects of the review stood out to the AI, which identifies the enthusiastic tone, detailed descriptions, timely delivery, reasonable price, and strong recommendation as key elements that create a compelling and persuasive review. The AI offers to explore any specific part of the review further.\n",
      "\n",
      "Exchange 6:\n",
      "Input: Would you recommend this restaurant based on the review?\n",
      "Response: Based on the positive review you shared, I would definitely recommend this restaurant! The review highlights several key factors that contribute to a great dining experience, such as timely delivery, high-quality pizza, and a reasonable price. The enthusiastic tone and strong recommendation from the reviewer suggest that they had a very satisfying experience, which is a good indicator for potential customers. If the restaurant consistently delivers on these aspects, it seems like a solid choice for anyone craving pizza. Would you like to know more about what to look for in restaurant reviews or perhaps explore other dining options?\n",
      "History: System: The human asks for the AI's opinion on a restaurant review they received. The AI expresses willingness to help and requests the review text along with specific aspects for feedback. The human shares a positive review about a Pizza Salami order, highlighting timely delivery, quality of the pizza, reasonable price, and overall satisfaction. The AI analyzes the review, noting its enthusiastic tone, detailed descriptions, appealing food qualities, value for money, and strong recommendation. The AI suggests that adding personal anecdotes or details about the restaurant's atmosphere could enhance the review, but overall considers it well-written and effective in conveying a positive dining experience. The human then asks what aspects of the review stood out to the AI, which identifies the enthusiastic tone, detailed descriptions, timely delivery, reasonable price, and strong recommendation as key elements that create a compelling and persuasive review. The AI offers to explore any specific part of the review further. The human inquires whether the AI thinks the price of $9.99 is reasonable for the pizza.\n",
      "AI: The price of $9.99 for a pizza can be considered reasonable, especially if the quality of the ingredients and the overall experience match the expectations set by the review. Factors like the size of the pizza, the type of toppings (like Salami), and the local market prices for similar offerings can also influence whether that price feels fair. If the pizza is well-made, delicious, and delivered promptly, then $9.99 seems like a good deal! Additionally, if the review mentions that the pizza exceeded expectations in terms of taste and quality, that further supports the idea that the price is justified. Would you like to discuss any other aspects of the review or the restaurant?\n",
      "\n",
      "Exchange 7:\n",
      "Input: What other information would you have liked to see in the review?\n",
      "Response: I would have liked to see a few additional details that could enhance the review even further. For instance:\n",
      "\n",
      "1. **Atmosphere and Ambiance**: Descriptions of the restaurant's interior, lighting, and overall vibe can help potential diners envision the experience. Was it cozy, modern, or family-friendly?\n",
      "\n",
      "2. **Service Quality**: Insights into the staff's friendliness, attentiveness, and efficiency can provide a fuller picture of the dining experience. Did the reviewer mention how they were treated?\n",
      "\n",
      "3. **Menu Variety**: Information about other menu items or specialties could be helpful. Did the reviewer try any appetizers, desserts, or drinks that stood out?\n",
      "\n",
      "4. **Personal Anecdotes**: Sharing a personal story or context about why they chose this restaurant or a memorable moment during their visit can make the review more relatable and engaging.\n",
      "\n",
      "5. **Comparison to Other Places**: If the reviewer has tried similar pizzas elsewhere, a comparison could provide context on how this restaurant stacks up against its competitors.\n",
      "\n",
      "Including these elements could make the review more comprehensive and informative for potential customers. Would you like to discuss any of these aspects in more detail?\n",
      "History: System: The human asks for the AI's opinion on a restaurant review they received. The AI expresses willingness to help and requests the review text along with specific aspects for feedback. The human shares a positive review about a Pizza Salami order, highlighting timely delivery, quality of the pizza, reasonable price, and overall satisfaction. The AI analyzes the review, noting its enthusiastic tone, detailed descriptions, appealing food qualities, value for money, and strong recommendation. The AI suggests that adding personal anecdotes or details about the restaurant's atmosphere could enhance the review, but overall considers it well-written and effective in conveying a positive dining experience. The human then asks what aspects of the review stood out to the AI, which identifies the enthusiastic tone, detailed descriptions, timely delivery, reasonable price, and strong recommendation as key elements that create a compelling and persuasive review. The AI offers to explore any specific part of the review further. The human inquires whether the AI thinks the price of $9.99 is reasonable for the pizza. The AI responds that $9.99 can be considered reasonable if the quality of the ingredients and overall experience match expectations, noting that factors like pizza size, toppings, and local market prices influence the perception of fairness. The AI concludes that if the pizza exceeded expectations in taste and quality, then the price is justified and offers to discuss other aspects of the review or restaurant.\n",
      "Human: Would you recommend this restaurant based on the review?\n",
      "AI: Based on the positive review you shared, I would definitely recommend this restaurant! The review highlights several key factors that contribute to a great dining experience, such as timely delivery, high-quality pizza, and a reasonable price. The enthusiastic tone and strong recommendation from the reviewer suggest that they had a very satisfying experience, which is a good indicator for potential customers. If the restaurant consistently delivers on these aspects, it seems like a solid choice for anyone craving pizza. Would you like to know more about what to look for in restaurant reviews or perhaps explore other dining options?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "\n",
    "# Create the summary memory with a token limit\n",
    "summary_memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=150)\n",
    "\n",
    "# Create a conversation chain\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=summary_memory\n",
    ")\n",
    "\n",
    "responses = []\n",
    "responses.append(conversation.invoke(input=\"Hello! I'd like to get your opinion on a restaurant review I received.\"))\n",
    "responses.append(conversation.invoke(input=\"Sure, I'd be happy to help! Could you share the review with me?\"))\n",
    "responses.append(conversation.invoke(input=\"\"\"Here's the review: I ordered Pizza Salami for 9.99$ and it was awesome! \n",
    "The pizza was delivered on time and was still hot when I received it. \n",
    "The crust was thin and crispy, and the toppings were fresh and flavorful. \n",
    "The Salami was well-cooked and complemented the cheese perfectly. \n",
    "The price was reasonable and I believe I got my money's worth. \n",
    "Overall, I am very satisfied with my order and I would recommend this pizza place to others.\"\"\"))\n",
    "responses.append(conversation.invoke(input=\"What aspects of the review stood out to you?\"))\n",
    "responses.append(conversation.invoke(input=\"Do you think the price of 9.99$ is reasonable for this pizza?\"))\n",
    "responses.append(conversation.invoke(input=\"Would you recommend this restaurant based on the review?\"))\n",
    "responses.append(conversation.invoke(input=\"What other information would you have liked to see in the review?\"))\n",
    "\n",
    "for i, response in enumerate(responses, 1):\n",
    "    print(f\"\\nExchange {i}:\")\n",
    "    print(f\"Input: {response['input']}\")\n",
    "    print(f\"Response: {response['response']}\")\n",
    "    print(f\"History: {response['history']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6a9198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
