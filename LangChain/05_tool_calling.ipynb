{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2777a53",
   "metadata": {},
   "source": [
    "# Tool Calling\n",
    "\n",
    "## Key Benefits\n",
    "\n",
    "* **Enhanced Functionality**: Perform complex tasks like data retrieval, calculations, or command execution.\n",
    "* **Structured Outputs**: Ensure outputs match predefined schemas for seamless data processing.\n",
    "* **Dynamic Decision-Making**: Invoke appropriate tools based on conversation context for intelligent interactions.\n",
    "* **Seamless Integration**: Enable smooth information flow across tools and components in workflows.\n",
    "* **Improved User Experience**: Provide accurate, relevant responses using real-time data or calculations.\n",
    "* **Flexibility & Customization**: Create custom tools to meet specific needs, enhancing application adaptability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ddb8b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d61189",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model=\"gpt-4o-mini\"\n",
    "llm = ChatOpenAI(temperature=0.0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fd9e9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm unable to provide real-time weather updates. For the latest weather information in Bangalore, I recommend checking a reliable weather website or app.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 16, 'total_tokens': 43, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-Bef2TsACAwUsISNS428jlBQVhMyNl', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--8f25fa82-9304-4636-9330-b3487a56c815-0', usage_metadata={'input_tokens': 16, 'output_tokens': 27, 'total_tokens': 43, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"How will the weather be in Bangalore today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95983c2",
   "metadata": {},
   "source": [
    "**LLM couldn't provide real-time weather updates**. Lets create a dummy tool to check whether in a specific city and allow LLMs to access these tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3e4bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "#defining different tools\n",
    "\n",
    "# @tool decorator creates LangChain tools\n",
    "\n",
    "@tool\n",
    "def fake_weather_api(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Check the weather in a specified city.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city where you want to check the weather.\n",
    "\n",
    "    Returns:\n",
    "        str: A description of the current weather in the specified city.\n",
    "    \"\"\"\n",
    "    return \"Sunny, 22Â°C\"  #this could be an external API, like Google Weather\n",
    "\n",
    "\n",
    "@tool\n",
    "def outdoor_seating_availability(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Check if outdoor seating is available at a specified restaurant in a given city.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city where you want to check for outdoor seating availability.\n",
    "\n",
    "    Returns:\n",
    "        str: A message stating whether outdoor seating is available or not.\n",
    "    \"\"\"\n",
    "    return \"Outdoor seating is available.\"\n",
    "\n",
    "\n",
    "tools = [fake_weather_api, outdoor_seating_availability]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c166a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools) # allows llms to access tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "450b7ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_IelFjmICdXQBl08Jx7vUu7HR', 'function': {'arguments': '{\"city\":\"Bangalore\"}', 'name': 'fake_weather_api'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 157, 'total_tokens': 173, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-Bef4aMzVGYI2qYKHc8LFMJHY2O6UE', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--beb9329f-358d-42fb-a34a-ff803669f501-0', tool_calls=[{'name': 'fake_weather_api', 'args': {'city': 'Bangalore'}, 'id': 'call_IelFjmICdXQBl08Jx7vUu7HR', 'type': 'tool_call'}], usage_metadata={'input_tokens': 157, 'output_tokens': 16, 'total_tokens': 173, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm_with_tools.invoke(\"How will the weather be in Bangalore today?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a278c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\n",
    "        \"How will the weather be in Bangalore today? Do you still have seats outdoor available?\"\n",
    "    )\n",
    "]\n",
    "\n",
    "result = llm_with_tools.invoke(messages)  #this only decides the tool to call\n",
    "messages.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc913c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'fake_weather_api',\n",
       "  'args': {'city': 'Bangalore'},\n",
       "  'id': 'call_Hsm0XbEy0REr4HjJzFvbcNHi',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'outdoor_seating_availability',\n",
       "  'args': {'city': 'Bangalore'},\n",
       "  'id': 'call_KdFv5uMCqjPSfYppRP5wduUS',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3f418fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_mapping = {\n",
    "    \"fake_weather_api\": fake_weather_api,\n",
    "    \"outdoor_seating_availability\": outdoor_seating_availability,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd8e94ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "# Iterate over each tool call in the result's tool_calls list\n",
    "for tool_call in result.tool_calls:\n",
    "\n",
    "    # Retrieve the corresponding tool from the tool_mapping dictionary using the tool name (case insensitive)\n",
    "    tool = tool_mapping[tool_call[\"name\"].lower()]\n",
    "\n",
    "    # Invoke the selected tool with the provided arguments and store the output\n",
    "    tool_output = tool.invoke(tool_call[\"args\"])\n",
    "\n",
    "    # Create a ToolMessage object with the tool's output and the unique ID of the tool call\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98942614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='How will the weather be in Bangalore today? Do you still have seats outdoor available?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Hsm0XbEy0REr4HjJzFvbcNHi', 'function': {'arguments': '{\"city\": \"Bangalore\"}', 'name': 'fake_weather_api'}, 'type': 'function'}, {'id': 'call_KdFv5uMCqjPSfYppRP5wduUS', 'function': {'arguments': '{\"city\": \"Bangalore\"}', 'name': 'outdoor_seating_availability'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 165, 'total_tokens': 216, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-Bef5e6x7iL82tHbDpQY3KzzGHduAG', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c74eafff-9c29-40c9-841c-2623dcd1c769-0', tool_calls=[{'name': 'fake_weather_api', 'args': {'city': 'Bangalore'}, 'id': 'call_Hsm0XbEy0REr4HjJzFvbcNHi', 'type': 'tool_call'}, {'name': 'outdoor_seating_availability', 'args': {'city': 'Bangalore'}, 'id': 'call_KdFv5uMCqjPSfYppRP5wduUS', 'type': 'tool_call'}], usage_metadata={'input_tokens': 165, 'output_tokens': 51, 'total_tokens': 216, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='Sunny, 22Â°C', tool_call_id='call_Hsm0XbEy0REr4HjJzFvbcNHi'),\n",
       " ToolMessage(content='Outdoor seating is available.', tool_call_id='call_KdFv5uMCqjPSfYppRP5wduUS')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfe9a150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The weather in Bangalore today is sunny with a temperature of 22Â°C. Additionally, outdoor seating is available at restaurants in the area.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 244, 'total_tokens': 272, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-Bef8951NIQnwLrIMX4r8Al34kkpnX', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--2c765d9e-0988-40c1-ab34-5ea8739bf01f-0', usage_metadata={'input_tokens': 244, 'output_tokens': 28, 'total_tokens': 272, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2c34ff",
   "metadata": {},
   "source": [
    "## Math Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c604831b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numexpr\n",
      "  Downloading numexpr-2.10.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /Users/thann/Library/CloudStorage/OneDrive-IndianInstituteofScience/Course_Contents/Deep Learning/Class Materials/Tutorials/deep-learning/.venv/lib/python3.9/site-packages (from numexpr) (2.0.2)\n",
      "Downloading numexpr-2.10.2-cp39-cp39-macosx_11_0_arm64.whl (134 kB)\n",
      "Installing collected packages: numexpr\n",
      "Successfully installed numexpr-2.10.2\n"
     ]
    }
   ],
   "source": [
    "!pip install numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7067c0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ce197fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x135c30e50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x135c30430>, root_client=<openai.OpenAI object at 0x1366199d0>, root_async_client=<openai.AsyncOpenAI object at 0x135c30370>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}))>, coroutine=<bound method Chain.arun of LLMMathChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x135c30e50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x135c30430>, root_client=<openai.OpenAI object at 0x1366199d0>, root_async_client=<openai.AsyncOpenAI object at 0x135c30370>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}))>)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "tool_names = [\"llm-math\"]\n",
    "tools = load_tools(tool_names, llm=llm)\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f52a20",
   "metadata": {},
   "source": [
    "## ReAct Template\n",
    "\n",
    "ReAct is a general paradigm that **combines reasoning and acting with LLMs**. ReAct prompts LLMs to generate verbal reasoning traces and actions for a task. This allows the system to perform dynamic reasoning to create, maintain, and adjust plans for acting while also enabling interaction to external environments (e.g., Wikipedia) to incorporate additional information into the reasoning. The figure below shows an example of ReAct and the different steps involved to perform question answering.\n",
    "\n",
    "<img src=\"react.webp\" width=500 height=500\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86e3b815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85579/1514226503.py:3: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(tools,\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "agent = initialize_agent(tools,\n",
    "                         llm,\n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, # Zero shot react prompt\n",
    "                         verbose=True,\n",
    "                         max_iterations=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "653f11d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe A-Team is a fictional group from a TV series. The main members of the A-Team include four key characters: Colonel John \"Hannibal\" Smith, Lieutenant Templeton \"Faceman\" Peck, Captain H. M. \"Howling Mad\" Murdock, and Sergeant Bosco \"B.A.\" Baracus. Therefore, I will conclude that the A-Team has 4 members. \n",
      "\n",
      "Final Answer: 4\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How many members does the A Team have?', 'output': '4'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\"input\":\"How many members does the A Team have?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc50c327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to first calculate \\( 100 \\times 100 \\) and then find the square root of the result. \n",
      "Action: Calculator \n",
      "Action Input: 100 * 100 \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 10000\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow that I have the result of \\( 100 \\times 100 \\), which is 10000, I need to calculate the square root of 10000. \n",
      "Action: Calculator \n",
      "Action Input: 10000**0.5 \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 100.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 100.0\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is 100 multiplied by 100? What is the square root of that number?',\n",
       " 'output': '100.0'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\"input\":\"What is 100 multiplied by 100? What is the square root of that number?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eecb865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
